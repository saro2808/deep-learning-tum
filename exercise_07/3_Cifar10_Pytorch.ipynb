{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR-pt-qFMTx0"
   },
   "source": [
    "# Notebook 3: Cifar10 Classification in Pytorch\n",
    "\n",
    "In this notebook, we will train an image classifier for the CIFAR-10 dataset, that you already know from exercise 6. Today, however, we will use the PyTorch framework which makes everything much more convenient!\n",
    "We will show you how to implement the deep learning pipeline in simple PyTorch. You could also, for the first time, utilize the GPUs on colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBqcIeuJMTx2"
   },
   "source": [
    "## (Optional) Mount in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjBDaPoXpHvt"
   },
   "source": [
    "### Set up PyTorch environment in colab\n",
    "\n",
    "For your regular environment this should already have been installed in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzL2MBcDqAsH"
   },
   "outputs": [],
   "source": [
    "# Optional: install correct libraries in google colab. Again, downgrade numpy and then RESTART the session! Runtime > Restart Session.\n",
    "# !python -m pip install \"numpy<2.0\" torch==2.2.2+cu121 torchvision==0.17.2+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !python -m pip install torchtext==0.17.2 torchaudio==2.2.2\n",
    "# !python -m pip install tensorboard==2.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UP5xfxQUMTx3"
   },
   "outputs": [],
   "source": [
    "# Use the following lines if you want to use Google Colab\n",
    "# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n",
    "# NOTE: terminate all other colab sessions that use GPU!\n",
    "# NOTE 2: Make sure the correct exercise folder (e.g exercise_07) is given.\n",
    "# OPTIONAL: Enable GPU via Runtime --> Change runtime type --> GPU\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_07'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEDWAZ7-ZA4E"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dJCiVLV5o9QO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvaj6myXS7nN"
   },
   "source": [
    "### Get Device\n",
    "In this exercise, we'll use PyTorch to build an image classifier for the CIFAR-10 dataset. As you know from exercise 06, processing a large set of images is quite computation extensive. Luckily, with PyTorch we're now able to make use of our GPU to significantly speed things up!\n",
    "\n",
    "In case you don't have a GPU, you can run this notebook on Google Colab where you can access a GPU for free!\n",
    "\n",
    "Of course, you can also run this notebook on your CPU only - though this is definitely not recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VWgm75NnS9hr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm_rTAPnpsUo"
   },
   "source": [
    "## Setup TensorBoard\n",
    "In exercise 07 you've already learned how to use TensorBoard. Let's use it again to make the debugging of our network and training process more convenient! Throughout this notebook, feel free to add further logs or visualizations to your TensorBoard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mI_Yf3JIMTx8"
   },
   "outputs": [],
   "source": [
    "# Delete previous instances of tensorboard\n",
    "import shutil\n",
    "tensorboard_path = os.path.abspath(\"logs\")\n",
    "if os.path.exists(tensorboard_path):\n",
    "    shutil.rmtree(tensorboard_path)\n",
    "os.makedirs(tensorboard_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOYbUg8lAmgU"
   },
   "source": [
    "### 2. Training & Validation Step\n",
    "Down below we've implemented the deep learning pipeline for you. Read it carefully, and see how things are implemented in PyTorch.\n",
    "Read the comments that explain each step of the pipline.\n",
    "\n",
    "But first, let's choose our hyperparameters!\n",
    "\n",
    "It could look something like this:\n",
    "\n",
    "```python\n",
    "hparams = {\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 3e-3,\n",
    "    \"n_hidden\": 180,\n",
    "    \"input_size\": 3 * 32 * 32,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_workers\": 2,\n",
    "    \"device\": device,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_3yd6SA_MTx9"
   },
   "outputs": [],
   "source": [
    "from exercise_code.MyPytorchModel import MyPytorchModel, CIFAR10DataModule\n",
    "# make sure you have downloaded the Cifar10 dataset on root: \"../datasets/cifar10\", if not, please check exercise 03.\n",
    "hparams = {}\n",
    "\n",
    "########################################################################\n",
    "# TODO: Define your hyper parameters here!                             #\n",
    "########################################################################\n",
    "\n",
    "hparams = {\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.7e-03,\n",
    "    'reg': 7.8e-07,\n",
    "    \"n_hidden\": 180,\n",
    "    \"input_size\": 3 * 32 * 32,\n",
    "    \"num_classes\": 10,\n",
    "    \"num_workers\": 8\n",
    "}\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "# Make sure you downloaded the CIFAR10 dataset already when using this cell\n",
    "# since we are showcasing the pytorch inhering ImageFolderDataset that\n",
    "# doesn't automatically download our data. Check exercise 3\n",
    "\n",
    "# If you want to switch to the memory dataset instead of image folder use\n",
    "# hparams[\"loading_method\"] = 'Memory'\n",
    "# The default is hparams[\"loading_method\"] = 'Image'\n",
    "# You will notice that it takes way longer to initialize a MemoryDataset\n",
    "# method because we have to load the data points into memory all the time.\n",
    "\n",
    "# You might get warnings below if you use too few workers. Pytorch uses\n",
    "# a more sophisticated Dataloader than the one you implemented previously.\n",
    "# In particular it uses multi processing to have multiple cores work on\n",
    "# individual data samples. You can enable more than workers (default=2)\n",
    "# via\n",
    "# hparams['num_workers'] = 8\n",
    "\n",
    "# Set up the data module including your implemented transforms\n",
    "data_module = CIFAR10DataModule(hparams)\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oulvt67yMTx9"
   },
   "source": [
    "Some tests to check whether we'll accept your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Ur0lLT_MMTx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: Your model has 0.621 params.\n",
      "Please don't use convolutions! For now, only use layers that have already been covered in the lecture!\n",
      "Model not accepted. Please follow the instructions.\n"
     ]
    }
   ],
   "source": [
    "model = MyPytorchModel(hparams)\n",
    "from exercise_code.Util import printModelInfo\n",
    "_ = printModelInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8v-5O-O7MTx9"
   },
   "outputs": [],
   "source": [
    "################## COLAB ##################\n",
    "# This might also work with jupyter notebooks, but will most likely not function well. Use the CMD/Terminal if possible (tensorboard --logdir=./)\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_uuzXMq6zjbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/3]: 100%|██████████████████████████████████████████████| 469/469 [00:06<00:00, 73.59it/s, curr_train_loss=1.18983806, lr=0.00056000]\n",
      "Validation Epoch [1/3]: 100%|█████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 114.59it/s, val_loss=2.84821540]\n",
      "Training Epoch [2/3]: 100%|██████████████████████████████████████████████| 469/469 [00:05<00:00, 82.12it/s, curr_train_loss=1.00968749, lr=0.00035840]\n",
      "Validation Epoch [2/3]: 100%|█████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 120.33it/s, val_loss=2.01737718]\n",
      "Training Epoch [3/3]: 100%|██████████████████████████████████████████████| 469/469 [00:05<00:00, 80.48it/s, curr_train_loss=0.86026916, lr=0.00022938]\n",
      "Validation Epoch [3/3]: 100%|█████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 118.60it/s, val_loss=1.51848892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished training!\n",
      "How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [00:03<00:00, 142.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 72.33000000000001%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 143.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Acc: 55.28999999999999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from exercise_code.MyPytorchModel import MyPytorchModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\"):\n",
    "    \"\"\"\n",
    "    Train the classifier for a number of epochs.\n",
    "    \"\"\"\n",
    "    loss_cutoff = len(train_loader) // 10\n",
    "    optimizer = torch.optim.Adam(model.parameters(), hparams[\"learning_rate\"])\n",
    "\n",
    "    # The scheduler is used to change the learning rate every few \"n\" steps.\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * len(train_loader) / 5), gamma=hparams.get('gamma', 0.8))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Training stage, where we want to update the parameters.\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        training_loss = []\n",
    "        validation_loss = []\n",
    "\n",
    "        # Create a progress bar for the training loop.\n",
    "        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n",
    "        for train_iteration, batch in training_loop:\n",
    "            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n",
    "            images, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n",
    "            images, labels = images.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n",
    "\n",
    "            # Flatten the images to a vector. This is done because the classifier expects a vector as input.\n",
    "            # Could also be done by reshaping the images in the dataset.\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            pred = model(images) # Stage 1: Forward().\n",
    "            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n",
    "            loss.backward()  # Stage 2: Backward().\n",
    "            optimizer.step() # Stage 3: Update the parameters.\n",
    "            scheduler.step() # Update the learning rate.\n",
    "\n",
    "\n",
    "            training_loss.append(loss.item())\n",
    "            training_loss = training_loss[-loss_cutoff:]\n",
    "\n",
    "            # Update the progress bar.\n",
    "            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(np.mean(training_loss)),\n",
    "                                      lr = \"{:.8f}\".format(optimizer.param_groups[0]['lr'])\n",
    "            )\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n",
    "\n",
    "        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n",
    "        # and \"with torch.no_grad()\" wrapper.\n",
    "        model.eval()\n",
    "        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_iteration, batch in val_loop:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                pred = model(images)\n",
    "                loss = loss_func(pred, labels)\n",
    "                validation_loss.append(loss.item())\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(val_loss = \"{:.8f}\".format(np.mean(validation_loss)))\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n",
    "\n",
    "\n",
    "# Create a tensorboard logger.\n",
    "# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n",
    "# Also, in order to reset the logs, delete the logs folder MANUALLY.\n",
    "\n",
    "path = \"logs\"\n",
    "num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n",
    "path = os.path.join(path, f'run_{num_of_runs + 1}')\n",
    "\n",
    "tb_logger = SummaryWriter(path)\n",
    "\n",
    "# Train the classifier.\n",
    "labled_train_loader = data_module.train_dataloader()\n",
    "labled_val_loader = data_module.val_dataloader()\n",
    "\n",
    "epochs = hparams.get('epochs', 3)\n",
    "loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n",
    "model = MyPytorchModel(hparams).to(device)\n",
    "train_model(model, labled_train_loader, labled_val_loader, loss_func, tb_logger, epochs=epochs, name=\"Default\")\n",
    "\n",
    "print()\n",
    "print(\"Finished training!\")\n",
    "print(\"How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\")\n",
    "print(f\"Training Acc: {model.getTestAcc(labled_train_loader)[1] * 100}%\")\n",
    "print(f\"Validation Acc: {model.getTestAcc(labled_val_loader)[1] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAp2OTyf4_5b"
   },
   "source": [
    "Now that everything is working, feel free to play around with different architectures. As you've seen, it's really easy to define your model or do changes there.\n",
    "\n",
    "To pass this submission, you'll need **50%** accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmEYmRT-5S-e"
   },
   "source": [
    "# Save your model & Report Test Accuracy\n",
    "\n",
    "When you've done with your **hyperparameter tuning**, have achieved **at least 50% validation accuracy** and are happy with your final model, you can save it here.\n",
    "\n",
    "Before that, we will check again whether the number of parameters is below 5 Mi and the file size is below 20 MB.\n",
    "\n",
    "When your final model is saved, we'll lastly report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "S69ETKxD5TcE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 127.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 55.28999999999999%\n",
      "FYI: Your model has 0.621 params.\n",
      "Please don't use convolutions! For now, only use layers that have already been covered in the lecture!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from exercise_code.Util import test_and_save\n",
    "\n",
    "test_and_save(model, data_module.val_dataloader(), data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmqQD0xiMTx_"
   },
   "source": [
    "Congrats! You've now finished your first image classifier in PyTorch! Much easier than in plain numpy, right? Time to get started with some more complex neural networks - see you at the next exercise!\n",
    "\n",
    "To create a zip file with your submission, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9BvMW-n9MTx_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant folders: ['exercise_code', 'models']\n",
      "notebooks files: ['1_pytorch.ipynb', '2_tensorboard.ipynb', '3_Cifar10_Pytorch.ipynb']\n",
      "Adding folder exercise_code\n",
      "Adding folder models\n",
      "324324324233\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ERROR: The folder 'models' is EMPTY! Make sure that the relevant cells ran properly and the relevant files were saved and then run the cell again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexercise_code\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msubmit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m submit_exercise\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msubmit_exercise\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../output/exercise07\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tum/deep-learning-tum/exercise_07/exercise_code/submit.py:61\u001b[39m, in \u001b[36msubmit_exercise\u001b[39m\u001b[34m(zip_output_filename, data_path, relevant_folders)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os.listdir(folder)) == \u001b[32m0\u001b[39m:\n\u001b[32m     59\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mERROR: The folder \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is EMPTY! Make sure that the relevant cells ran properly \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33m            and the relevant files were saved and then run the cell again.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(msg.split()))\n\u001b[32m     63\u001b[39m myzip.write(folder)\n\u001b[32m     64\u001b[39m zipdir(folder, myzip)\n",
      "\u001b[31mException\u001b[39m: ERROR: The folder 'models' is EMPTY! Make sure that the relevant cells ran properly and the relevant files were saved and then run the cell again."
     ]
    }
   ],
   "source": [
    "from exercise_code.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/exercise07')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQbY4sYtMTx_"
   },
   "source": [
    "# Submission Instructions\n",
    "\n",
    "Congratulations! You've just built your first image classifier with PyTorch! To complete the exercise, submit your final model to our submission portal - you probably know the procedure by now.\n",
    "\n",
    "1. Go on [our submission page](https://i2dl.vc.in.tum.de/), register for an account and login. We use your matriculation number and send an email with the login details to the mail account associated. When in doubt, login into tum online and check your mails there. You will get an ID which we need in the next step.\n",
    "2. Log into [our submission page](https://i2dl.vc.in.tum.de/) with your account details and upload the `zip` file. Once successfully uploaded, you should be able to see the submitted file selectable on the top.\n",
    "3. Click on this file and run the submission script. You will get an email with your score as well as a message if you have surpassed the threshold.\n",
    "\n",
    "# Submission Goals\n",
    "\n",
    "- Goal: Successfully implement a a fully connected NN image classifier for CIFAR-10 with PyTorch.\n",
    "\n",
    "- Passing Criteria: Similar to the last exercise, there are no unit tests that check specific components of your code. The only thing that's required to pass this optional submission, is your model to reach at least **50% accuracy** on __our__ test dataset. The submission system will show you a number between 0 and 100 which corresponds to your accuracy.\n",
    "\n",
    "- You can make **$\\infty$** submissions until the end of the semester. Remember that this exercise is an __OPTIONAL SUBMISSION__ and will __not__ be counted for the bonus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "54970da6898dad277dbf355945c2dee7f942d2a31ec1fc1455b6d4f552d07b83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
